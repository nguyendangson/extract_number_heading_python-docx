{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/70/1a/7edeedb1c089d63ccd8bd5c0612334774e90cf9337de9fe6c82d90081791/ipywidgets-8.1.2-py3-none-any.whl.metadata\n",
      "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (8.17.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (5.13.0)\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets)\n",
      "  Obtaining dependency information for widgetsnbextension~=4.0.10 from https://files.pythonhosted.org/packages/99/bc/82a8c3985209ca7c0a61b383c80e015fd92e74f8ba0ec1af98f9d6ca8dce/widgetsnbextension-4.0.10-py3-none-any.whl.metadata\n",
      "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets)\n",
      "  Obtaining dependency information for jupyterlab-widgets~=3.0.10 from https://files.pythonhosted.org/packages/24/da/db1cb0387a7e4086780aff137987ee924e953d7f91b2a870f994b9b1eeb8/jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.41)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.10)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\a485205\\appdata\\roaming\\python\\python311\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/139.4 kB ? eta -:--:--\n",
      "   ----------------- --------------------- 61.4/139.4 kB 656.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 139.4/139.4 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "   ---------------------------------------- 0.0/215.0 kB ? eta -:--:--\n",
      "   ----------------------------- --------- 163.8/215.0 kB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 215.0/215.0 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/2.3 MB 6.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.4/2.3 MB 4.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.3 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.3 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.8/2.3 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.3 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.4/2.3 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.3 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.9/2.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.0/2.3 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.2/2.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.2 jupyterlab-widgets-3.0.10 widgetsnbextension-4.0.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#%pip install python-docx\n",
    "#%pip install git+https://github.com/python-openxml/cxml.git\n",
    "#%pip install docx2txt\n",
    "#%pip install aspose-words\n",
    "#%pip install docx2pdf\n",
    "%pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "from docx import Document\n",
    "from cxml import xml\n",
    "import os\n",
    "import docx2txt                           # Extract images\n",
    "from docx.text.paragraph import Paragraph\n",
    "import zipfile\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image\n",
    "from docx.shared import Inches\n",
    "import aspose.words as aw\n",
    "import docx2pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\A485205\\\\Desktop\\\\Hackathon\\\\openai-hackathon'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\A485205\\\\Desktop\\\\Hackathon\\\\openai-hackathon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docx path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "# doc_path = './input_docx/P6700 ITM Vol 1 - Intro, Scope, Competition.docx'\n",
    "# folder_name = './output_docx/P6700 ITM Vol 1 - Intro, Scope, Competition'\n",
    "\n",
    "#doc_path = './input_docx/P6700 ITM Vol 2 - Design, Market, and Values.docx'\n",
    "\n",
    "#doc_path = './input_docx/P6700 ITM Vol 3 - Feature Targets, Testing.docx'\n",
    "\n",
    "#doc_path = './input_docx/P6700 ITM Vol 4 - Platform, Models, Packages, Adaptation.docx' \n",
    "\n",
    "#doc_path = './input_docx/P6700 ITM Vol 5 - Advanced Driver Assistance Safety Systems.docx' \n",
    "\n",
    "doc_path = './input_docx/P6700 ITM Vol 6 - Powertrain, Programmable Features.docx'     # Error?\n",
    "folder_name = './output_docx/P6700 ITM Vol 6 - Powertrain, Programmable Features' \n",
    "\n",
    "# doc_path = './input_docx/P6700 ITM Vol 7 - Axles, Chassis, Trailer Body Connections, Tires & Wheels.docx' \n",
    "# folder_name = './output_docx/P6700 ITM Vol 7 - Axles, Chassis, Trailer Body Connections, Tires & Wheels'\n",
    "\n",
    "# doc_path = './input_docx/P6700 ITM Vol 8 - Cab, Lighting, Audio, Equipment.docx'\n",
    "# folder_name = './output_docx/P6700 ITM Vol 8 - Cab, Lighting, Audio, Equipment'\n",
    "\n",
    "# doc_path = './input_docx/P6700 ITM Vol 9 - Business Services, Aftermarket, Warranty.docx' \n",
    "# folder_name = './output_docx/P6700 ITM Vol 9 - Business Services, Aftermarket, Warranty' \n",
    "\n",
    "# os.path.exists(doc_path)\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    \n",
    "\n",
    "\n",
    "#folder_name = './output_docx/P6700 ITM Vol 2 - Design, Market, and Values'\n",
    "#folder_name = './output_docx/P6700 ITM Vol 3 - Feature Targets, Testing'\n",
    "#folder_name = './output_docx/P6700 ITM Vol 4 - Platform, Models, Packages, Adaptation' \n",
    "#folder_name = './output_docx/P6700 ITM Vol 5 - Advanced Driver Assistance Safety Systems'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pdf paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = './input_docx/P6700 ITM Vol 6 - Powertrain, Programmable Features.pdf'     # Error?\n",
    "folder_name = './output_docx/P6700 ITM Vol 6 - Powertrain, Programmable Features' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from typing import Generator, Tuple, Union\n",
    "\n",
    "from docx import Document\n",
    "from docx.document import Document as DocType\n",
    "from docx.oxml.table import CT_Tbl\n",
    "from docx.oxml.text.paragraph import CT_P\n",
    "from docx.oxml.xmlchemy import BaseOxmlElement\n",
    "from docx.text.paragraph import Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterparts(doc_path:str, skip_first=True, bias:int=0) -> Generator[Tuple[int,DocType],None,None]:\n",
    "    \"\"\"Iterate over sub-documents by splitting source document into parts\n",
    "    Split into parts by copying source document and cutting off unrelevant\n",
    "    data.\n",
    "\n",
    "    Args:\n",
    "        doc_path (str):                 path to source *docx* file\n",
    "        skip_first (bool, optional):    skip first split point and wait for \n",
    "                                        second occurrence. Defaults to True.\n",
    "        bias (int, optional):           split point bias. Defaults to 0.\n",
    "\n",
    "    Yields:\n",
    "        Generator[Tuple[int,DocType],None,None]:    first element of each tuple \n",
    "                                                    indicates the number of a \n",
    "                                                    sub-document, if number is 0 \n",
    "                                                    then there are no sub-documents\n",
    "    \"\"\"\n",
    "    doc = Document(doc_path)\n",
    "    counter = 0\n",
    "    while doc:\n",
    "        split_elem_idx = -1\n",
    "        doc_body = doc.element.body\n",
    "        cutted = [doc, None]\n",
    "        for idx, elem in enumerate(doc_body.iterchildren()):\n",
    "            if is_split_point(elem):\n",
    "                if split_elem_idx == -1 and skip_first:\n",
    "                    split_elem_idx = idx\n",
    "                else:\n",
    "                    cutted = split(doc, idx+bias) # idx-1 to keep previous paragraph\n",
    "                    counter += 1\n",
    "                    break\n",
    "        yield (counter, cutted[0])\n",
    "        doc = cutted[1]\n",
    "\n",
    "def is_split_point(element:BaseOxmlElement) -> bool:\n",
    "    \"\"\"Split criteria\n",
    "\n",
    "    Args:\n",
    "        element (BaseOxmlElement): oxml element\n",
    "\n",
    "    Returns:\n",
    "        bool: whether the *element* is the beginning of a new sub-document\n",
    "    \"\"\"\n",
    "    if isinstance(element, CT_P):\n",
    "        p = Paragraph(element, element.getparent())\n",
    "        return p.text.startswith(\"Some text\")\n",
    "    return False\n",
    "\n",
    "def split(doc:DocType, cut_idx:int) -> Tuple[DocType,DocType]:\n",
    "    \"\"\"Splitting into parts by copying source document and cutting of\n",
    "    unrelevant data.\n",
    "\n",
    "    Args:\n",
    "        doc (DocType): [description]\n",
    "        cut_idx (int): [description]\n",
    "\n",
    "    Returns:\n",
    "        Tuple[DocType,DocType]: [description]\n",
    "    \"\"\"\n",
    "    tmpdocfile = write_tmp_doc(doc)\n",
    "    second_part = doc\n",
    "    second_elems = list(second_part.element.body.iterchildren())\n",
    "    for i in range(0, cut_idx):\n",
    "        remove_element(second_elems[i])\n",
    "    first_part = Document(tmpdocfile)\n",
    "    first_elems = list(first_part.element.body.iterchildren())\n",
    "    for i in range(cut_idx, len(first_elems)):\n",
    "        remove_element(first_elems[i])\n",
    "    tmpdocfile.close()\n",
    "    return (first_part, second_part)\n",
    "\n",
    "def remove_element(elem: Union[CT_P,CT_Tbl]):\n",
    "    elem.getparent().remove(elem)\n",
    "\n",
    "def write_tmp_doc(doc:DocType):\n",
    "    tmp = tempfile.TemporaryFile()\n",
    "    doc.save(tmp)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert docx to pdf and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx2pdf import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "convert(doc_path, doc_path.replace('docx','pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling a docx template with Python while preserving style\n",
    "https://blog.xa0.de/post/Filling-a-docx-template-with-Python-while-preserving-style/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "# Load your document\n",
    "doc = Document(doc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock data for placeholders\n",
    "mock_data = {\n",
    "    \"PLACEHOLDER1\": \"replacement text\",\n",
    "    \"PLACEHOLDER2\": \"another piece of text\"\n",
    "    # Add as many placeholders as needed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace text without changing style\n",
    "def replace_text_preserve_style(paragraph, key, value):\n",
    "    if key in paragraph.text:\n",
    "        inline = paragraph.runs\n",
    "        for i in range(len(inline)):\n",
    "            if key in inline[i].text:\n",
    "                text = inline[i].text.replace(key, value)\n",
    "                inline[i].text = text\n",
    "\n",
    "# Replace placeholders with mock data\n",
    "for paragraph in doc.paragraphs:\n",
    "    for key in mock_data:\n",
    "        replace_text_preserve_style(paragraph, key, mock_data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the modified document\n",
    "doc.save(f'{folder_name}/path_to_modified_document.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using aspose.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = aw.Document(doc_path)\n",
    "pageCount = doc.page_count\n",
    "pageCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aspose.words.saving.SaveOutputParameters object at 0x0000018BBB27C090>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the document to HTML format.\n",
    "doc.save(f\"{folder_name}/test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aspose.words.saving.SaveOutputParameters object at 0x000001E28612A990>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract range of pages\n",
    "extractedPages = doc.extract_pages(7, 1)\n",
    "\n",
    "# save pages as a separate document\n",
    "extractedPages.save(f\"{folder_name}/split_by_page_range.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Word document\n",
    "doc = aw.Document(doc_path)\n",
    "\n",
    "for i in range(0, doc.sections.count) :\n",
    "            \n",
    "    # clone the section to split\n",
    "    section = doc.sections[i].clone()\n",
    "\n",
    "    # create an instance of Document class for new doucment\n",
    "    newDoc = aw.Document()\n",
    "    \n",
    "    # clear the default sections\n",
    "    newDoc.sections.clear()\n",
    "\n",
    "    # inster section into new document\n",
    "    newSection = newDoc.import_node(section, True).as_section()\n",
    "    newDoc.sections.add(newSection)\n",
    "\n",
    "\n",
    "    # Save section as a separate document\n",
    "    newDoc.save(f\"folder_name/Sec{i}.docx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docx as a zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(doc_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('./output_docx/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = zipfile.ZipFile(doc_path)\n",
    "for file in archive.filelist:\n",
    "    archive.extract(file, 'extracted_docx')\n",
    "#for file in os.listdir('./output_docx/text'):\n",
    "    if file.endswith('.emf'):\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract number, name headings and their page numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract number and name headings       \n",
    "def extract_number_heading(doc_path: str):\n",
    "    '''\n",
    "    Input: path of a docx file \n",
    "    Output: a list of heading names and their number headings corresponding chapters, sections, subsections,... \n",
    "    '''\n",
    "    doc = Document(doc_path)\n",
    "    # Extract chapters, section, subsection numbers\n",
    "    heading_numbers=[]\n",
    "    heading_name=[]\n",
    "\n",
    "    for paragraph in doc.paragraphs:\n",
    "        # Check if the paragraph is a heading\n",
    "        if paragraph.style.name.startswith('Heading'):            # Heading for all chapters, sections, subsections,.., Heading 1 for chapter, Heading 2 for subsections, Heading 3 for subsubsections\n",
    "            # Save heading_numbers       \n",
    "            heading_numbers.append(paragraph.style.name.split()[1])\n",
    "            heading_name.append((paragraph.text))\n",
    "    #print(heading_numbers)\n",
    "    \n",
    "    # Map heading_numbers to heading sections\n",
    "    heading_sections_result = []\n",
    "    chapter = 1\n",
    "    for i in range(len(heading_numbers)):\n",
    "        if heading_numbers[i] =='1':\n",
    "            heading_sections_result.append(str(chapter))\n",
    "            chapter+=1\n",
    "        else:\n",
    "            if int(heading_numbers[i]) > int(heading_numbers[i-1]):\n",
    "\n",
    "                if int(heading_numbers[i]) == 2:\n",
    "                    heading_sections_result.append(heading_sections_result[-1]+'.1')\n",
    "                else:\n",
    "                    heading_sections_result.append(heading_sections_result[-1] + '.1'*(int(heading_numbers[i])-2))\n",
    "\n",
    "\n",
    "            elif int(heading_numbers[i]) == int(heading_numbers[i-1]):\n",
    "                u = heading_sections_result[-1].split('.')\n",
    "                u[-1] = str(int(u[-1])+1)\n",
    "                heading_sections_result.append('.'.join(u))\n",
    "       \n",
    "            elif int(heading_numbers[i]) < int(heading_numbers[i-1]):\n",
    "                u = heading_sections_result[-1].split('.')\n",
    "                u = u[:int(heading_numbers[i])]\n",
    "                u[-1] = str(int(u[-1])+1)\n",
    "                heading_sections_result.append('.'.join(u))\n",
    "    \n",
    "    # Combine heading_name and heading_sections_result \n",
    "    total_heading = []\n",
    "    for i in range(len(heading_numbers)):\n",
    "        total_heading.append(heading_sections_result[i] + ' ' + heading_name[i])\n",
    "\n",
    "    return total_heading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting documents and keeping images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting documents and keeping images\n",
    "def save_content_under_headings(doc_path, folder_name):\n",
    "\n",
    "    \n",
    "    # Load the Word document\n",
    "    doc = Document(doc_path)\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    \n",
    "    # Create a new folder\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    current_heading = None\n",
    "    current_doc = None\n",
    "    \n",
    "    doc_name = doc_path.split('/')[-1]\n",
    "    doc_name = '['+ ''.join(doc_name.split(\".\")[0]) +']' + ' '\n",
    "    heading_name_list = extract_number_heading(doc_path)\n",
    "    k=-1\n",
    "\n",
    "    # Create a new folder images\n",
    "    path_folder_images = folder_name + '_images'\n",
    "    if not os.path.exists(path_folder_images):\n",
    "        os.makedirs(path_folder_images)\n",
    "\n",
    "    # Extract images\n",
    "    # with zipfile.ZipFile(doc_path, 'r') as zip_ref:\n",
    "    #     zip_ref.extractall(path_folder_images)\n",
    "    #docx2txt.process(doc_path, path_folder_images)\n",
    "\n",
    "    # Images name\n",
    "    rels = {}\n",
    "    for r in doc.part.rels.values():\n",
    "        if isinstance(r._target, docx.parts.image.ImagePart):\n",
    "            if ('.png' in r._target.partname) or ('.jpg' in r._target.partname) or ('.emf' in r._target.partname):\n",
    "                rels[r.rId] = os.path.basename(r._target.partname)\n",
    "    rels = dict(sorted(rels.items()))\n",
    "    #print(rels)\n",
    "\n",
    "    # Start splitting\n",
    "    for paragraph in doc.paragraphs:\n",
    "        # Check if the paragraph is a heading\n",
    "        if paragraph.style.name.startswith('Heading'):            # Heading for all chapters, sections, subsections,.., Heading 1 for chapter, Heading 2 for subsections, Heading 3 for subsubsections\n",
    "            # Save the previous section if there is one           \n",
    "            #print(paragraph.style.name.split()[1])\n",
    "\n",
    "            # Advoid special characters in headings to save file\n",
    "            current_heading = heading_name_list[k]\n",
    "            current_heading = current_heading.replace('/', '-').replace('\\\\', '-').replace('\\t','')\n",
    "\n",
    "            for s in ['*', '\"', '<', '>', '|', '?', ':']:\n",
    "                current_heading = current_heading.replace(s, '')\n",
    "\n",
    "            k+=1\n",
    "\n",
    "            if current_heading and current_doc:\n",
    "                file_path = os.path.join(folder_name, f\"{doc_name}{current_heading}.docx\")\n",
    "\n",
    "                try:\n",
    "                    current_doc.save(file_path)\n",
    "                except:\n",
    "                    print('Errors file path:', file_path)\n",
    "                    errors.append(current_heading)\n",
    "                    pass\n",
    "            \n",
    "            # Reset for the next section\n",
    "            current_heading = heading_name_list[k]\n",
    "            current_heading = current_heading.replace('/', '-').replace('\\\\', '-').replace('\\t','')\n",
    "            current_doc = Document()\n",
    "\n",
    "            current_doc.add_heading(current_heading, level=0)           \n",
    "\n",
    "        else:\n",
    "            # Accumulate content under the current heading\n",
    "            if current_doc is not None:\n",
    "                current_doc.add_paragraph(paragraph.text)\n",
    "\n",
    "                # Input images\n",
    "                #if 'graphicData' in paragraph._p.xml:\n",
    "                if 'Graphic' in paragraph._p.xml:\n",
    "\n",
    "                  \n",
    "                    # Get the rId of the image\n",
    "                    for rId in rels:\n",
    "                        if rId in paragraph._p.xml:\n",
    "\n",
    "                            path_image = path_folder_images + '\\\\word\\\\media' +'\\\\' + rels[rId]\n",
    "                            \n",
    "                            # with open(path_image, \"rb\") as f:\n",
    "                            #     image = base64.b64encode(f.read()).decode(\"utf-8\")                     \n",
    "                            #     current_doc.add_picture(io.BytesIO(image))\n",
    "\n",
    "                            if '.emf' in rels[rId]:\n",
    "                                # # get sizes of the emf image\n",
    "                                # with open(path_image, \"rb\") as f:\n",
    "                                #     f.read(16)\n",
    "                                #     w1, w2 = f.read(1).hex(), f.read(1).hex()\n",
    "                                #     f.read(2)\n",
    "                                #     h1, h2 = f.read(1).hex(), f.read(1).hex()\n",
    "\n",
    "                                # width  = int(str(w2) + str(w1), 16) * 762\n",
    "                                # height = int(str(h2) + str(h1), 16) * 762\n",
    "\n",
    "                                path_image_png = path_folder_images + '\\\\word\\\\media' +'\\\\' + rels[rId].split('.')[0] + '.png'\n",
    "                                Image.open(path_image).save(path_image_png)\n",
    "\n",
    "                                # img = Image.open(path_image)\n",
    "\n",
    "                                # img = img.resize((width, height), Image.LANCZOS)\n",
    "\n",
    "                                # img.save(path_image_png)\n",
    "\n",
    "                                current_doc.add_picture(path_image_png, width=Inches(0.5), height=Inches(2))\n",
    "                            else:\n",
    "                                current_doc.add_picture(path_image)\n",
    "\n",
    "\n",
    "                            \n",
    "    # Don't forget to save the last section\n",
    "    if current_heading and current_doc:\n",
    "        current_heading = heading_name_list[k]\n",
    "        current_heading = current_heading.replace('/', '-').replace('\\\\', '-').replace('\\t','')\n",
    "        for s in ['*', '\"', '<', '>', '|', '?', ':']:\n",
    "            current_heading = current_heading.replace(s, '')\n",
    "\n",
    "        file_path = os.path.join(folder_name, f\"{current_heading}.docx\")\n",
    "        try:\n",
    "            current_doc.save(file_path)\n",
    "        except:\n",
    "            errors.append(current_heading)\n",
    "            print('Errors file path:', file_path)\n",
    "            pass\n",
    "    \n",
    "    if len(errors)>1:\n",
    "        file = open(os.path.join(folder_name, 'sections_errors.txt'), 'w')\n",
    "        file.write('\\n\\n'.join(errors))\n",
    "        file.close()\n",
    "    \n",
    "    # End of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors file path: ./output_docx/P6700 ITM Vol 6 - Powertrain, Programmable Features\\[P6700 ITM Vol 6 - Powertrain, Programmable Features] 3.2 Transmission Electronics Package (295) Still ok except the shifter has changed. - JBB.docx\n",
      "Errors file path: ./output_docx/P6700 ITM Vol 6 - Powertrain, Programmable Features\\[P6700 ITM Vol 6 - Powertrain, Programmable Features] 3.9 Roll Direction Change Inhibit (E3E) (VHD ONLY) – To be inhibited on all B1 B2, to be introduced with Vocational in 2027.docx\n",
      "Errors file path: ./output_docx/P6700 ITM Vol 6 - Powertrain, Programmable Features\\[P6700 ITM Vol 6 - Powertrain, Programmable Features] 4.83 Additional Road Speed Limit (8KB) – will need to review for GHG VNL or VHD intro.docx\n"
     ]
    }
   ],
   "source": [
    "save_content_under_headings(doc_path, folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing all docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['./input_docx/P6700 ITM Vol 6 - Powertrain, Programmable Features.docx',\n",
       "  './output_docx/P6700 ITM Vol 6 - Powertrain, Programmable Features'],\n",
       " ['./input_docx/P6700 ITM Vol 7 - Axles, Chassis, Trailer Body Connections, Tires & Wheels.docx',\n",
       "  './output_docx/P6700 ITM Vol 7 - Axles, Chassis, Trailer Body Connections, Tires & Wheels'],\n",
       " ['./input_docx/P6700 ITM Vol 8 - Cab, Lighting, Audio, Equipment.docx',\n",
       "  './output_docx/P6700 ITM Vol 8 - Cab, Lighting, Audio, Equipment'],\n",
       " ['./input_docx/P6700 ITM Vol 9 - Business Services, Aftermarket, Warranty.docx',\n",
       "  './output_docx/P6700 ITM Vol 9 - Business Services, Aftermarket, Warranty']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = []\n",
    "for file_name in os.listdir('./input_docx/'):\n",
    "    doc_path = f'./input_docx/{file_name}'\n",
    "    folder_name = f'./output_docx/{file_name.split(\".\")[0]}'\n",
    "\n",
    "    check.append([doc_path, folder_name])\n",
    "\n",
    "check = check[:-1]\n",
    "check \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract images\n",
    "for [doc_path, folder_name] in check:\n",
    "    # Create a new folder images\n",
    "    path_folder_images = folder_name + '_images'\n",
    "    if not os.path.exists(path_folder_images):\n",
    "        os.makedirs(path_folder_images)\n",
    "\n",
    "    # Extract images\n",
    "    with zipfile.ZipFile(doc_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path_folder_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully: [P6700 ITM Vol 1 - Intro, Scope, Competition] 5.5 Market Strategy.docx\n",
      "Successfully: [P6700 ITM Vol 2 - Design, Market, and Values] 3.7 Focused Product Training Areas.docx\n",
      "Successfully: [P6700 ITM Vol 3 - Feature Targets, Testing] 7.2.2 Sun Simulation Testing and Climate Testing .docx\n",
      "Successfully: [P6700 ITM Vol 4 - Platform, Models, Packages, Adaptation] 5.9 GHG Application .docx\n",
      "Successfully: [P6700 ITM Vol 5 - Advanced Driver Assistance Safety Systems] 1.18 Rear Monitoring, Class II & IV (W5E) V1.4 Intro.docx\n",
      "Successfully: [P6700 ITM Vol 6 - Powertrain, Programmable Features] 4.95 Fleet Management System Gateway (MJX).docx\n",
      "Successfully: [P6700 ITM Vol 7 - Axles, Chassis, Trailer Body Connections, Tires & Wheels] 8.3 Tire Pressure Monitoring (3CE).docx\n",
      "Successfully: [P6700 ITM Vol 8 - Cab, Lighting, Audio, Equipment] 7.1 Cab Paint Scheme Guidelines.docx\n",
      "Successfully: [P6700 ITM Vol 9 - Business Services, Aftermarket, Warranty] 7 Warranty.docx\n"
     ]
    }
   ],
   "source": [
    "for [doc_path, folder_name] in check:\n",
    "    save_content_under_headings(doc_path, folder_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do: save_content_under_headings for all docx in a folder\n",
    "for file_name in os.listdir('./input_docx/'):\n",
    "    doc_path = f'./input_docx/{file_name}'\n",
    "    folder_name = f'./output_docx/{file_name.split(\".\")[0]}'\n",
    "    save_content_under_headings(doc_path, folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if  not os.path.exists(folder_name):\n",
    "#     os.makedirs(folder_name)\n",
    "    \n",
    "# text = docx2txt.process(doc_path, folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "# doc = Document(doc_path)\n",
    "# image_paragraphs = []   \n",
    "\n",
    "# for paragraph in doc.paragraphs:\n",
    "#     if 'graphicData' in paragraph._p.xml:\n",
    "#     #if paragragph_contains_image(paragraph):\n",
    "#         image_paragraphs.append(paragraph._p.xml)\n",
    "\n",
    "# len(image_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Test\n",
    "# doc = Document(doc_path)\n",
    "# image_paragraphs = []   \n",
    "\n",
    "# for paragraph in doc.paragraphs:\n",
    "#     if 'Graphic' in paragraph._p.xml:\n",
    "#     #if paragragph_contains_image(paragraph):\n",
    "#         image_paragraphs.append(paragraph._p.xml)\n",
    "\n",
    "# len(image_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doc = Document(doc_path)\n",
    "# image_paragraphs = []\n",
    "# for s in doc.inline_shapes:\n",
    "#     image_paragraphs.append([s.height, s.width, s._inline.graphic.graphicData.pic.nvPicPr.cNvPr.name])\n",
    "\n",
    "# len (image_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 5, 57, 60, 64, 69, 78, 87, 92, 98, 101, 104, 110, 116, 124, 160, 346, 385, 402, 418, 423, 434, 446]\n"
     ]
    }
   ],
   "source": [
    "# doc = Document(doc_path)\n",
    "\n",
    "# paraGr = []             \n",
    "# index = []            # index of images \n",
    "\n",
    "# par = doc.paragraphs\n",
    "# for i in range(len(par)):\n",
    "#      paraGr.append(par[i].text)\n",
    "#      if 'graphicData' in par[i]._p.xml:\n",
    "#          index.append(i)\n",
    "\n",
    "# print(index)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do: save_content_under_headings for all docx in a folder\n",
    "# for file_name in os.listdir('./input_docx/'):\n",
    "#     doc_path = f'./input_docx/{file_name}'\n",
    "#     folder_name = f'./output_docx/{file_name.split(\".\")[0]}'\n",
    "#     save_content_under_headings(doc_path, folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 Executive Summary',\n",
       " '2 Document Guidelines for Contributors',\n",
       " '3 Introduction',\n",
       " '3.1 Historical and Project Background',\n",
       " '3.2 Industry Regulations, Vehicle Credit System  ',\n",
       " '3.3 Strategic Overview',\n",
       " '3.4 Project Overview',\n",
       " '3.4.1.1 Documentation & Specification Strategy for Producing GHG Credits',\n",
       " '3.4.1.2 Powertrain Installation',\n",
       " '3.4.1.3 Group Electrical Architecture',\n",
       " '3.4.2 Project profile',\n",
       " '4 Competitive Offer',\n",
       " '5 Project Scope (from Project Description document)',\n",
       " '5.1 Prerequisites',\n",
       " '5.2 Product offering (BPS)',\n",
       " '5.3 Forecasted volumes',\n",
       " '5.4 Introduction Timing (Note, this timing is fluid)',\n",
       " '5.5 Market Strategy']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_number_heading(doc_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
